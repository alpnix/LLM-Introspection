# LLM Introspection

This repository aims to implement the research paper: [Signs of introspection in large language models](https://www.anthropic.com/research/introspection) by Anthropic.

## Overview

This project explores introspective capabilities in large language models, investigating whether AI systems can accurately report on their own internal states and mechanisms via a technique introduced as "concept injection".
